# ============================================
# docker-compose.yml
# ============================================

version: '3.8'

services:
  # PostgreSQL - Banco de dados principal
  postgres:
    image: postgres:15-alpine
    container_name: infohub-postgres
    environment:
      POSTGRES_DB: infohub
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin123}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - infohub-network

  # Redis - Cache e filas
  redis:
    image: redis:7-alpine
    container_name: infohub-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis123}
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - infohub-network

  # MinIO - Storage S3-compat√≠vel
  minio:
    image: minio/minio:latest
    container_name: infohub-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD:-minioadmin123}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - infohub-network

  # Elasticsearch - Logs e busca
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: infohub-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - infohub-network

  # API - Backend principal
  api:
    build:
      context: .
      dockerfile: docker/api.Dockerfile
    container_name: infohub-api
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3000
      
      # Database
      DATABASE_URL: postgresql://admin:${POSTGRES_PASSWORD:-admin123}@postgres:5432/infohub
      
      # Redis
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis123}@redis:6379
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis123}
      
      # Storage
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_USER:-minioadmin}
      S3_SECRET_KEY: ${MINIO_PASSWORD:-minioadmin123}
      S3_BUCKET: infohub-storage
      S3_PUBLIC_URL: http://localhost:9000/infohub-storage
      
      # Auth
      JWT_SECRET: ${JWT_SECRET:-seu-jwt-secret-muito-seguro-aqui}
      JWT_EXPIRATION: 24h
      
      # APIs Externas
      HIBP_API_KEY: ${HIBP_API_KEY}
      SERASA_API_KEY: ${SERASA_API_KEY}
      
      # Elasticsearch
      ELASTICSEARCH_URL: http://elasticsearch:9200
      
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./packages/api:/app/packages/api
      - ./packages/shared:/app/packages/shared
      - /app/node_modules
    networks:
      - infohub-network
    restart: unless-stopped

  # Worker - Processamento background
  worker:
    build:
      context: .
      dockerfile: docker/worker.Dockerfile
    container_name: infohub-worker
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      
      # Redis
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis123}@redis:6379
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis123}
      
      # Database
      DATABASE_URL: postgresql://admin:${POSTGRES_PASSWORD:-admin123}@postgres:5432/infohub
      
      # Storage
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_USER:-minioadmin}
      S3_SECRET_KEY: ${MINIO_PASSWORD:-minioadmin123}
      S3_BUCKET: infohub-storage
      
      # APIs Externas
      HIBP_API_KEY: ${HIBP_API_KEY}
      
    depends_on:
      - api
      - redis
      - postgres
    volumes:
      - ./packages/worker:/app/packages/worker
      - ./packages/shared:/app/packages/shared
      - /app/node_modules
    networks:
      - infohub-network
    deploy:
      replicas: 2
    restart: unless-stopped

  # Frontend - Interface Web
  frontend:
    build:
      context: .
      dockerfile: docker/frontend.Dockerfile
    container_name: infohub-frontend
    ports:
      - "3001:3001"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      NEXT_PUBLIC_API_URL: http://localhost:3000
      NEXT_PUBLIC_WS_URL: ws://localhost:3000
    depends_on:
      - api
    volumes:
      - ./packages/frontend:/app/packages/frontend
      - ./packages/shared:/app/packages/shared
      - /app/node_modules
      - /app/.next
    networks:
      - infohub-network
    restart: unless-stopped

  # Nginx - Reverse Proxy (Produ√ß√£o)
  nginx:
    image: nginx:alpine
    container_name: infohub-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
      - frontend
    networks:
      - infohub-network
    profiles:
      - production

volumes:
  postgres_data:
  redis_data:
  minio_data:
  elasticsearch_data:

networks:
  infohub-network:
    driver: bridge

---
# ============================================
# .env.example
# ============================================

# Application
NODE_ENV=development
JWT_SECRET=seu-jwt-secret-muito-seguro-mude-isso

# Database
POSTGRES_PASSWORD=admin123

# Redis
REDIS_PASSWORD=redis123

# MinIO
MINIO_USER=minioadmin
MINIO_PASSWORD=minioadmin123

# External APIs
HIBP_API_KEY=sua-chave-haveibeenpwned
SERASA_API_KEY=sua-chave-serasa

---
# ============================================
# docker/init-db.sql - Cria√ß√£o de tabelas
# ============================================

-- Usu√°rios
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(255) NOT NULL,
    api_key VARCHAR(255) UNIQUE,
    subscription_plan VARCHAR(50) DEFAULT 'FREE',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Logs de consultas (LGPD compliance)
CREATE TABLE IF NOT EXISTS query_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    query_type VARCHAR(50) NOT NULL,
    query_data JSONB NOT NULL,
    ip_address VARCHAR(45),
    user_agent TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_user_queries (user_id, created_at),
    INDEX idx_query_type (query_type)
);

-- Cache de CNPJs
CREATE TABLE IF NOT EXISTS cnpj_cache (
    cnpj VARCHAR(14) PRIMARY KEY,
    data JSONB NOT NULL,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Processos encontrados
CREATE TABLE IF NOT EXISTS processos (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    numero VARCHAR(50) UNIQUE NOT NULL,
    tribunal VARCHAR(10) NOT NULL,
    data JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_numero (numero)
);

-- Relat√≥rios gerados
CREATE TABLE IF NOT EXISTS reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    type VARCHAR(50) NOT NULL,
    data JSONB NOT NULL,
    pdf_url TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Assinaturas
CREATE TABLE IF NOT EXISTS subscriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    plan VARCHAR(50) NOT NULL,
    queries_limit INT NOT NULL,
    queries_used INT DEFAULT 0,
    valid_until TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

---
# ============================================
# scripts/start.sh
# ============================================

#!/bin/bash

echo "üöÄ Iniciando InfoHub Pro..."

# 1. Verificar se .env existe
if [ ! -f .env ]; then
    echo "üìù Criando arquivo .env..."
    cp .env.example .env
    echo "‚ö†Ô∏è  ATEN√á√ÉO: Edite o arquivo .env com suas credenciais!"
    exit 1
fi

# 2. Construir imagens
echo "üî® Construindo imagens Docker..."
docker-compose build

# 3. Iniciar containers
echo "üê≥ Iniciando containers..."
docker-compose up -d postgres redis minio elasticsearch

# 4. Aguardar servi√ßos ficarem prontos
echo "‚è≥ Aguardando servi√ßos..."
sleep 10

# 5. Criar bucket no MinIO
echo "üì¶ Configurando MinIO..."
docker-compose exec -T minio mc alias set myminio http://localhost:9000 minioadmin minioadmin123
docker-compose exec -T minio mc mb myminio/infohub-storage
docker-compose exec -T minio mc policy set download myminio/infohub-storage

# 6. Rodar migra√ß√µes
echo "üóÑÔ∏è  Executando migra√ß√µes..."
docker-compose exec -T api npm run migrate

# 7. Iniciar aplica√ß√£o
echo "üéØ Iniciando aplica√ß√£o..."
docker-compose up -d api worker frontend

echo ""
echo "‚úÖ InfoHub Pro est√° rodando!"
echo ""
echo "üìç URLs:"
echo "   - Frontend: http://localhost:3001"
echo "   - API: http://localhost:3000"
echo "   - MinIO Console: http://localhost:9001"
echo "   - Elasticsearch: http://localhost:9200"
echo ""
echo "üìä Para ver logs:"
echo "   docker-compose logs -f"
echo ""
echo "üõë Para parar:"
echo "   docker-compose down"

---
# ============================================
# package.json (root)
# ============================================

{
  "name": "infohub-pro",
  "version": "1.0.0",
  "private": true,
  "workspaces": [
    "packages/*"
  ],
  "scripts": {
    "dev": "turbo run dev",
    "build": "turbo run build",
    "start": "turbo run start",
    "docker:build": "docker-compose build",
    "docker:up": "docker-compose up -d",
    "docker:down": "docker-compose down",
    "docker:logs": "docker-compose logs -f",
    "docker:restart": "docker-compose restart",
    "setup": "chmod +x scripts/start.sh && ./scripts/start.sh",
    "clean": "turbo run clean && docker-compose down -v"
  },
  "devDependencies": {
    "turbo": "^1.10.0",
    "typescript": "^5.0.0",
    "@types/node": "^20.0.0"
  }
}

---
# ============================================
# Comandos para come√ßar
# ============================================

# 1. Clone ou crie o projeto
mkdir infohub-pro && cd infohub-pro

# 2. Instale depend√™ncias
npm install

# 3. Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env com suas credenciais

# 4. Execute o setup
npm run setup

# 5. Acesse a aplica√ß√£o
# Frontend: http://localhost:3001
# API: http://localhost:3000
# MinIO: http://localhost:9001

# Ver logs
npm run docker:logs

# Parar tudo
npm run docker:down

---
# ============================================
# README.md
# ============================================

# InfoHub Pro

Plataforma profissional de intelig√™ncia e due diligence 100% legal e em compliance com LGPD.

## ‚ö° Features

‚úÖ **Consulta CNPJ** - API oficial Receita Federal
‚úÖ **Processos Judiciais** - Busca em tribunais p√∫blicos  
‚úÖ **OSINT √âtico** - Intelig√™ncia de fontes abertas
‚úÖ **KYC/KYB** - Verifica√ß√£o de identidade e empresas
‚úÖ **Relat√≥rios** - Gera√ß√£o autom√°tica de PDFs

## üöÄ Quick Start

```bash
# Instalar
npm install

# Configurar
cp .env.example .env

# Iniciar
npm run setup
```

## üìö Documenta√ß√£o

- API Docs: http://localhost:3000/docs
- Legal: ./docs/legal/
- Deployment: ./docs/deployment/

## ‚öñÔ∏è Legal

Esta plataforma est√° em compliance com:
- ‚úÖ LGPD (Lei Geral de Prote√ß√£o de Dados)
- ‚úÖ Marco Civil da Internet
- ‚úÖ C√≥digo Penal Brasileiro

**Uso permitido apenas para fins leg√≠timos.**

## üìÑ Licen√ßa

MIT License - Veja LICENSE para detalhes